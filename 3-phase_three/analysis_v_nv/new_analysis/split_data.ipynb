{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob as gl\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dt_v_nv = '/Users/alduck/Documents/Github/mt_industrial_usecase/SpecialIssue_PROFES/MutationAnalisys/Analysis/analysis_v_nv/new_analysis/hmr3_td_v_nv.json'\n",
    "\n",
    "with open(path_dt_v_nv, 'r') as file:\n",
    "    td_v_nv = json.load(file)\n",
    "\n",
    "td_v = td_v_nv['v_td']\n",
    "td_nv = td_v_nv['no_v_td']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HMR3 = '/Users/alduck/Documents/Github/mt_industrial_usecase/SpecialIssue_PROFES/MutationAnalisys/Analysis/analysis_step_3/Num1390Line153Vers1/final_MR1_Num1390Line153Vers1.json'\n",
    "\n",
    "storage_path_td_nv = '/Users/alduck/Documents/Github/mt_industrial_usecase/SpecialIssue_PROFES/MutationAnalisys/Analysis/analysis_v_nv/new_analysis/td_nv/'\n",
    "storage_path_td_v = '/Users/alduck/Documents/Github/mt_industrial_usecase/SpecialIssue_PROFES/MutationAnalisys/Analysis/analysis_v_nv/new_analysis/td_v/'\n",
    "with open(path_HMR3, 'r') as file:\n",
    "    mr3 = json.load(file)\n",
    "filtered_data_v = {}\n",
    "for key2 in td_v:\n",
    "    filtered_data_v.update({key: value for key, value in mr3.items() if key == key2})\n",
    "filtered_data_nv = {}\n",
    "for key2 in td_nv:\n",
    "    filtered_data_nv.update({key: value for key, value in mr3.items() if key == key2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path  = '/Users/alduck/Documents/Github/mt_industrial_usecase/SpecialIssue_PROFES/MutationAnalisys/Analysis/analysis_step_3/*'\n",
    "all_paths = gl.glob(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'final_MR1_' + folder_name + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'hmr1/' + taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'hmr1/'+taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'final_MR2_' + folder_name + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'hmr2/' + taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'hmr2/'+taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = gl.glob('/Users/alduck/Documents/Github/mt_industrial_usecase/SpecialIssue_PROFES/MutationAnalisys/not_crased_mutated_files_all_inputs/*')\n",
    "\n",
    "for path in data_paths:\n",
    "    \n",
    "\n",
    "    # Extract the folder name\n",
    "    folder_name = path.split('/')[-1]\n",
    "    file_path = 'Results_MR3Sum_' + folder_name + '.json'\n",
    "    # Define the target file name\n",
    "    target_path = os.path.join(path, file_path)  \n",
    "    \n",
    "    output_name_v = storage_path_td_v + 'hmr3/' + file_path\n",
    "    output_name_nv = storage_path_td_nv + 'hmr3/'+file_path\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'gmr1_mul' + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'gm1/' + folder_name + '_' +taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'gm1/' + folder_name + '_' +taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        print(mr)\n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'gmr2_exc' + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'gm2/' + folder_name + '_' +taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'gm2/' + folder_name + '_' +taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'gmr3_inc' + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'gm3/' + folder_name + '_' +taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'gm3/' + folder_name + '_' +taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'gmr4_inv' + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'gm4/' + folder_name + '_' +taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'gm4/' + folder_name + '_' +taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'gmr5_ref' + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'gm5/' + folder_name + '_' +taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'gm5/' + folder_name + '_' +taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_paths:\n",
    "    folder_name = path.split('/')[-1]\n",
    "    taget_file = 'gmr6_dupli' + '.json'\n",
    "    target_path = os.path.join(path, taget_file)\n",
    "    output_name_v = storage_path_td_v + 'gm6/' + folder_name + '_' +taget_file\n",
    "    output_name_nv = storage_path_td_nv + 'gm6/' + folder_name + '_' +taget_file\n",
    "    try:\n",
    "        with open(target_path, 'r') as file:\n",
    "            mr = json.load(file)\n",
    "        \n",
    "        filtered_data_v = {}\n",
    "        for key2 in td_v:\n",
    "            try:\n",
    "                filtered_data_v.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "        \n",
    "        filtered_data_nv = {}\n",
    "        for key2 in td_nv:\n",
    "            try:\n",
    "                filtered_data_nv.update({key: value for key, value in mr.items() if key == key2})\n",
    "            except:\n",
    "                print(key2, 'not found')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    with open(output_name_v, 'w') as json_file:\n",
    "        json.dump(filtered_data_v, json_file, indent = 4 )\n",
    "    with open(output_name_nv, 'w') as json_file:\n",
    "        json.dump(filtered_data_nv, json_file, indent = 4 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
